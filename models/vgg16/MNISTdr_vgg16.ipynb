{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "MNISTdr_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true,
        "id": "Sh-iZSpH4Ofz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers ,regularizers\n",
        "from keras.layers import Input, Add, Dense, Activation,BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D,Dropout\n",
        "from keras.models import Model\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator # for Data augmentation\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "4KYXgXUg4Of5"
      },
      "source": [
        "def loadData():\n",
        "    ''' read training and testing images and reshape it to (m,28*28) and also read training labels\n",
        "    \n",
        "    - parameters \n",
        "    \n",
        "        - no inputs\n",
        "\n",
        "        - outputs :\n",
        "            - trainingX : np array of shape (42000 ,28,28) contain training images \n",
        "            - trainingY : np array of shape (42000 ,) contain training data labels \n",
        "            - testX : np array of shape(28000,28,28)\n",
        "    '''\n",
        "    \n",
        "    # trainPath = \"../input/train.csv\"\n",
        "    # testPath = \"../input/test.csv\"\n",
        "    # training_frame = pd.DataFrame(pd.read_csv(trainPath))\n",
        "    # test_frame = pd.DataFrame(pd.read_csv(testPath))\n",
        "    # trainingY = np.array(training_frame['label'])\n",
        "    # index = [\"pixel\"+str(x) for x in range(784)] # generate list of columns indices of data frame to read pixels value by it \n",
        "    # trainingX = np.array(training_frame[index])\n",
        "    # trainingX= trainingX.reshape(trainingX.shape[0],28,28,1)\n",
        "    # testX = np.array(test_frame[index])\n",
        "    # testX = testX.reshape(testX.shape[0],28,28,1)\n",
        "\n",
        "    # LOADING DATA\n",
        "    # Loading Data\n",
        "    handwriting_mnist = keras.datasets.mnist\n",
        "    (train_images,train_labels),(test_images,test_labels) = handwriting_mnist.load_data()\n",
        "    train_images = train_images.reshape(len(train_images),28,28,1)\n",
        "    test_images = test_images.reshape(len(test_images),28,28,1)\n",
        "\n",
        "    return train_images, train_labels , test_images, test_labels\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d35a060d13581901912116326f4b2bc8a6d5f3b9",
        "collapsed": true,
        "id": "ygEqy4kx4Of6"
      },
      "source": [
        "trainingX , trainingY , testX, testY = loadData()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "aade795c84ae40f7d2bda6522cc43c5be2e7380e",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NktVSh24Of7",
        "outputId": "da1fe8bd-f7df-45f0-8a0e-ca0cd3503b95"
      },
      "source": [
        "# checking the dimensions\n",
        "print(\"training x : \",trainingX.shape)\n",
        "print(\"training y : \",trainingY.shape)\n",
        "print(\"test x : \",testX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training x :  (60000, 28, 28, 1)\n",
            "training y :  (60000,)\n",
            "test x :  (10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "28e046e46b09a4d280c91c9301537aef360584e4",
        "id": "FWlTFnZr4Of7"
      },
      "source": [
        "def oneHot(y):\n",
        "    ''' convert labels into one hot coding \n",
        "        parameters:\n",
        "            - input : list of labels \n",
        "            - output : np array of one hot encoding \n",
        "    '''\n",
        "    encoder = LabelBinarizer()\n",
        "    y = encoder.fit_transform(y)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "feb3bc9d09abec8989efcc6fa2e199fe42ab0ccc",
        "id": "lQSA7j8e4Of8"
      },
      "source": [
        "# this fun plot example of our images data \n",
        "def plot_figures(x,y,nrows = 3, ncols=4):\n",
        "    \"\"\"Plot random figures of data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : Images\n",
        "    y : labels\n",
        "    ncols : number of columns of subplots wanted in the display\n",
        "    nrows : number of rows of subplots wanted in the figure\n",
        "    \"\"\"\n",
        "    # generate random indexs \n",
        "    indexs = random.sample(range(0, len(y)), nrows*ncols)\n",
        "    \n",
        "    x = x.reshape(x.shape[0],28,28)\n",
        "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows,figsize=(10,10))\n",
        "    for ind,i in enumerate(indexs):\n",
        "        axeslist.ravel()[ind].imshow(x[i], cmap=plt.gray())\n",
        "        axeslist.ravel()[ind].set_title(y[i])\n",
        "        axeslist.ravel()[ind].set_axis_off()\n",
        "    #plt.tight_layout() # optional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "563a967cae0c97056b43acd79e61fdfeae65b1ee",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "dMp2uaHY4Of9",
        "outputId": "6e26ecc7-b9d1-44b4-dfed-37b801e877dd"
      },
      "source": [
        "plot_figures(x = trainingX , y = trainingY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 12 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "40096ffe3fca2e7940898c0e76e2c8adf0a27392",
        "id": "vB5sjzl54Of-"
      },
      "source": [
        "## build our model \n",
        "def vgg16(trainingX , trainingY):\n",
        "    \"\"\" implmentation of VGG16 model\n",
        "    \n",
        "    args:\n",
        "        input:\n",
        "            - trainingX : np array contain training data \n",
        "            - trainingY : np array contain training labels with out one hot coding -we will do this later in this fuc - \n",
        "            \n",
        "        output:\n",
        "            - mode : our keras mode of VGG16 \n",
        "            - trainingY : return training y after one hot encoding\n",
        "    \n",
        "    Architecture :\n",
        "            -> conv3-64 -> conv3-64\n",
        "            -> maxpool \n",
        "            -> conv3-128 ->  conv3-128\n",
        "            -> maxpool\n",
        "            -> conv3-256 -> conv3-256 -> conv1-256\n",
        "            -> maxpool\n",
        "            -> conv3-512 -> conv3-512 -> conv1-512\n",
        "            -> maxpool\n",
        "            -> conv3-512 -> conv3-512 -> conv1-512\n",
        "            -> maxpool\n",
        "            -> FC100 'relu'\n",
        "            -> FC50 'relu'\n",
        "            -> FC10  'softmax'\n",
        "            \n",
        "    \"\"\"\n",
        "\n",
        "    # create input tensor \n",
        "    inputShape = trainingX.shape\n",
        "    modelInput = Input(inputShape[1:])\n",
        "    x = modelInput\n",
        "    print(x.shape)\n",
        "    # one hot encoding for our labels\n",
        "    trainingY = oneHot(trainingY)\n",
        "    \n",
        "    # normalization \n",
        "    trainingX = trainingX /255.0\n",
        "    print(trainingY.shape)\n",
        "    # build the model\n",
        "    \n",
        "    x = Conv2D(64,(3,3),padding=\"same\", input_shape=(28,28,1),activation = 'relu',strides=(1,1),name='conv1',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(64,(3,3),padding=\"same\",activation = 'relu',strides=(1,1),name='conv2',kernel_initializer='glorot_uniform')(x)\n",
        "    \n",
        "    x =   MaxPooling2D((3, 3), strides=(2, 2) ,padding =\"same\",name=\"maxpool1\")(x)\n",
        "    \n",
        "    x = Conv2D(128,(3,3),padding=\"same\",activation = 'relu',strides=(1,1),name='conv3',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(128,(3,3),padding=\"same\",strides=(1,1),name='conv4',kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    \n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2) ,padding =\"same\",name=\"maxpool2\")(x)\n",
        "    \n",
        "    x = Conv2D(256,(3,3),padding=\"same\",strides=(1,1),activation = 'relu',name='conv5',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(256,(3,3),padding=\"same\",strides=(1,1),activation = 'relu',name='conv6',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(256,(1,1),padding=\"same\",strides=(1,1),activation = 'relu',name='conv7',kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    \n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2) ,padding =\"valid\",name=\"maxpool3\")(x)\n",
        "\n",
        "    x = Conv2D(512,(3,3),padding=\"same\",strides=(1,1),activation = 'relu',name='conv8',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(512,(3,3),padding=\"same\",strides=(1,1),activation = 'relu',name='conv9',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(512,(1,1),padding=\"same\",strides=(1,1),activation = 'relu',name='conv10',kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    \n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2) ,padding =\"same\",name=\"maxpool4\")(x)\n",
        "    \n",
        "    x = Conv2D(512,(3,3),padding=\"same\",strides=(1,1),activation = 'relu',name='conv11',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(512,(3,3),padding=\"same\",strides=(1,1),activation = 'relu',name='conv12',kernel_initializer='glorot_uniform')(x)\n",
        "    x = Conv2D(512,(1,1),padding=\"same\",strides=(1,1),activation = 'relu',name='conv13',kernel_initializer='glorot_uniform',kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "    \n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2) ,padding =\"same\",name=\"maxpool5\")(x)\n",
        "    \n",
        "    #flatten x to be FC in next layer\n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    #fc layers\n",
        "    x = Dense(100,name=\"fc1\", kernel_initializer = 'glorot_uniform',activation='relu')(x)\n",
        "    x = Dense(100,name=\"fc2\", kernel_initializer = 'glorot_uniform',activation='relu')(x)\n",
        "    x = Dense(10,name=\"fc3\", kernel_initializer = 'glorot_uniform',activation='softmax')(x)\n",
        "\n",
        "    #model\n",
        "    model = Model(inputs = modelInput, outputs = x, name='vgg16')\n",
        "\n",
        "    return model,trainingY\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3d5af295ec9981caad1bfcc378eb94fcb9046079",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkT0NKUo4Of_",
        "outputId": "636893a4-f452-4795-e231-1e0d1ddb6692"
      },
      "source": [
        "model,trainingY = vgg16(trainingX,trainingY)\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 28, 28, 1)\n",
            "(60000, 10)\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " conv2 (Conv2D)              (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " maxpool1 (MaxPooling2D)     (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv3 (Conv2D)              (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " conv4 (Conv2D)              (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " maxpool2 (MaxPooling2D)     (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv5 (Conv2D)              (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv6 (Conv2D)              (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " conv7 (Conv2D)              (None, 7, 7, 256)         65792     \n",
            "                                                                 \n",
            " maxpool3 (MaxPooling2D)     (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " conv8 (Conv2D)              (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " conv9 (Conv2D)              (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " conv10 (Conv2D)             (None, 3, 3, 512)         262656    \n",
            "                                                                 \n",
            " maxpool4 (MaxPooling2D)     (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv11 (Conv2D)             (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv12 (Conv2D)             (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv13 (Conv2D)             (None, 2, 2, 512)         262656    \n",
            "                                                                 \n",
            " maxpool5 (MaxPooling2D)     (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 100)               51300     \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 100)               10100     \n",
            "                                                                 \n",
            " fc3 (Dense)                 (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,057,354\n",
            "Trainable params: 10,057,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "aa02188b32f9354d4eff7a35d319c8b4f38a611a",
        "id": "w_p_24cy4OgB"
      },
      "source": [
        "# reduce LR \n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ae70d1ef98021df45ed03c692ddba2f41d16f03f",
        "collapsed": true,
        "id": "1iL81_eT4OgC"
      },
      "source": [
        "# Data augmentation\n",
        "aug  = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        data_format = 'channels_last')  # randomly flip images\n",
        "aug.fit(trainingX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4df75c39e571e4b253f1b168b1812f0c1edf434c",
        "id": "RKWVvtCk4OgC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainingX, X_val, trainingY, Y_val = train_test_split(trainingX, trainingY, test_size = 0.1, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "20e201e74ff80565e094dad5dba913c4d75b9fd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM9svvCb4OgD",
        "outputId": "29aa6267-46ac-4752-a5a3-7508ca055d2d"
      },
      "source": [
        "modelHistory = model.fit_generator(aug.flow(trainingX,\n",
        "                    trainingY,batch_size = 64),\n",
        "                    epochs = 40,\n",
        "                    validation_data=(X_val,Y_val), \n",
        "                    shuffle=True,\n",
        "                    verbose = 2,\n",
        "                    callbacks = [lr_reduce])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "844/844 - 68s - loss: 2.6893 - accuracy: 0.7808 - val_loss: 0.5586 - val_accuracy: 0.9697 - lr: 0.0010 - 68s/epoch - 80ms/step\n",
            "Epoch 2/40\n",
            "844/844 - 52s - loss: 0.3770 - accuracy: 0.9671 - val_loss: 0.1871 - val_accuracy: 0.9808 - lr: 0.0010 - 52s/epoch - 62ms/step\n",
            "Epoch 3/40\n",
            "844/844 - 52s - loss: 0.2103 - accuracy: 0.9747 - val_loss: 0.1639 - val_accuracy: 0.9820 - lr: 0.0010 - 52s/epoch - 61ms/step\n",
            "Epoch 4/40\n",
            "844/844 - 52s - loss: 0.1768 - accuracy: 0.9763 - val_loss: 0.1777 - val_accuracy: 0.9778 - lr: 0.0010 - 52s/epoch - 61ms/step\n",
            "Epoch 5/40\n",
            "844/844 - 52s - loss: 0.1571 - accuracy: 0.9797 - val_loss: 0.1559 - val_accuracy: 0.9800 - lr: 0.0010 - 52s/epoch - 61ms/step\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "844/844 - 52s - loss: 0.1448 - accuracy: 0.9811 - val_loss: 0.1799 - val_accuracy: 0.9795 - lr: 0.0010 - 52s/epoch - 61ms/step\n",
            "Epoch 7/40\n",
            "844/844 - 52s - loss: 0.0861 - accuracy: 0.9885 - val_loss: 0.0725 - val_accuracy: 0.9900 - lr: 5.0000e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 8/40\n",
            "844/844 - 52s - loss: 0.0728 - accuracy: 0.9897 - val_loss: 0.0823 - val_accuracy: 0.9877 - lr: 5.0000e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 9/40\n",
            "844/844 - 52s - loss: 0.0730 - accuracy: 0.9894 - val_loss: 0.0705 - val_accuracy: 0.9893 - lr: 5.0000e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "844/844 - 52s - loss: 0.0720 - accuracy: 0.9891 - val_loss: 0.0653 - val_accuracy: 0.9898 - lr: 5.0000e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 11/40\n",
            "844/844 - 51s - loss: 0.0521 - accuracy: 0.9927 - val_loss: 0.0429 - val_accuracy: 0.9938 - lr: 2.5000e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 12/40\n",
            "844/844 - 51s - loss: 0.0460 - accuracy: 0.9929 - val_loss: 0.0458 - val_accuracy: 0.9932 - lr: 2.5000e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 13/40\n",
            "844/844 - 52s - loss: 0.0430 - accuracy: 0.9932 - val_loss: 0.0412 - val_accuracy: 0.9942 - lr: 2.5000e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 14/40\n",
            "844/844 - 52s - loss: 0.0413 - accuracy: 0.9937 - val_loss: 0.0408 - val_accuracy: 0.9947 - lr: 2.5000e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 15/40\n",
            "844/844 - 51s - loss: 0.0405 - accuracy: 0.9935 - val_loss: 0.0429 - val_accuracy: 0.9938 - lr: 2.5000e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 16/40\n",
            "844/844 - 51s - loss: 0.0406 - accuracy: 0.9932 - val_loss: 0.0424 - val_accuracy: 0.9943 - lr: 2.5000e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "844/844 - 51s - loss: 0.0398 - accuracy: 0.9931 - val_loss: 0.0445 - val_accuracy: 0.9925 - lr: 2.5000e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 18/40\n",
            "844/844 - 51s - loss: 0.0302 - accuracy: 0.9955 - val_loss: 0.0321 - val_accuracy: 0.9957 - lr: 1.2500e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 19/40\n",
            "844/844 - 52s - loss: 0.0274 - accuracy: 0.9959 - val_loss: 0.0335 - val_accuracy: 0.9952 - lr: 1.2500e-04 - 52s/epoch - 61ms/step\n",
            "Epoch 20/40\n",
            "844/844 - 51s - loss: 0.0253 - accuracy: 0.9959 - val_loss: 0.0389 - val_accuracy: 0.9937 - lr: 1.2500e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "844/844 - 51s - loss: 0.0260 - accuracy: 0.9955 - val_loss: 0.0294 - val_accuracy: 0.9953 - lr: 1.2500e-04 - 51s/epoch - 61ms/step\n",
            "Epoch 22/40\n",
            "844/844 - 51s - loss: 0.0218 - accuracy: 0.9966 - val_loss: 0.0269 - val_accuracy: 0.9957 - lr: 6.2500e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 23/40\n",
            "844/844 - 51s - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.0271 - val_accuracy: 0.9962 - lr: 6.2500e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 24/40\n",
            "844/844 - 51s - loss: 0.0188 - accuracy: 0.9970 - val_loss: 0.0287 - val_accuracy: 0.9958 - lr: 6.2500e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 25/40\n",
            "844/844 - 51s - loss: 0.0180 - accuracy: 0.9975 - val_loss: 0.0282 - val_accuracy: 0.9958 - lr: 6.2500e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "844/844 - 51s - loss: 0.0173 - accuracy: 0.9972 - val_loss: 0.0251 - val_accuracy: 0.9960 - lr: 6.2500e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 27/40\n",
            "844/844 - 51s - loss: 0.0160 - accuracy: 0.9978 - val_loss: 0.0251 - val_accuracy: 0.9958 - lr: 3.1250e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 28/40\n",
            "844/844 - 51s - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.0273 - val_accuracy: 0.9950 - lr: 3.1250e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "844/844 - 51s - loss: 0.0151 - accuracy: 0.9976 - val_loss: 0.0267 - val_accuracy: 0.9958 - lr: 3.1250e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 30/40\n",
            "844/844 - 51s - loss: 0.0140 - accuracy: 0.9981 - val_loss: 0.0269 - val_accuracy: 0.9952 - lr: 1.5625e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 31/40\n",
            "844/844 - 51s - loss: 0.0142 - accuracy: 0.9978 - val_loss: 0.0260 - val_accuracy: 0.9960 - lr: 1.5625e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "844/844 - 51s - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.0266 - val_accuracy: 0.9962 - lr: 1.5625e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 33/40\n",
            "844/844 - 51s - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0259 - val_accuracy: 0.9958 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 34/40\n",
            "844/844 - 51s - loss: 0.0125 - accuracy: 0.9983 - val_loss: 0.0265 - val_accuracy: 0.9957 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 35/40\n",
            "844/844 - 51s - loss: 0.0122 - accuracy: 0.9983 - val_loss: 0.0261 - val_accuracy: 0.9960 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 36/40\n",
            "844/844 - 51s - loss: 0.0118 - accuracy: 0.9983 - val_loss: 0.0262 - val_accuracy: 0.9957 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 37/40\n",
            "844/844 - 51s - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.0254 - val_accuracy: 0.9958 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 38/40\n",
            "844/844 - 51s - loss: 0.0116 - accuracy: 0.9984 - val_loss: 0.0262 - val_accuracy: 0.9960 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 39/40\n",
            "844/844 - 51s - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.0262 - val_accuracy: 0.9957 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n",
            "Epoch 40/40\n",
            "844/844 - 51s - loss: 0.0123 - accuracy: 0.9982 - val_loss: 0.0259 - val_accuracy: 0.9955 - lr: 1.0000e-05 - 51s/epoch - 61ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "993885c6b36b25aca539bdd07406f95ea1a9a899",
        "id": "ziT-FOlx4OgD"
      },
      "source": [
        "def plotModelHistory(modeHistory):\n",
        "    # summarize history for accuracy\n",
        "    history = modeHistory\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b84442a64048149a81be11b524bd5dd93e172ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "JK5Ty31n4OgD",
        "outputId": "659c96a0-43e4-4a1b-e6f2-dc54bebef71e"
      },
      "source": [
        "plotModelHistory(modelHistory)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cd763ec4e9b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotModelHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelHistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-e83a85372cda>\u001b[0m in \u001b[0;36mplotModelHistory\u001b[0;34m(modeHistory)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "fa370f7165b0988e0f772c819f67073a498bc8ce",
        "id": "6TVzUg0D4OgE"
      },
      "source": [
        "#save model\n",
        "model.save_weights('vgg16_wieghts.h5')\n",
        "model.save('vgg16-digitRecognizer_keras.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d8af094c8338e194ee8f6846571670909258f358",
        "id": "0q__qhO04OgE"
      },
      "source": [
        "# create array for testY\n",
        "m = testX.shape[0]\n",
        "testY = np.zeros((m,1))\n",
        "testY = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK8LiSGa98TE",
        "outputId": "5d29e3d9-3568-418b-8185-288f32397410"
      },
      "source": [
        "model.evaluate(testX,oneHot(testY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0198 - accuracy: 0.9960\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.019807148724794388, 0.9959999918937683]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwXLay3fJTqd",
        "outputId": "49e7530b-3aaf-48f7-9a06-9f58044e9344"
      },
      "source": [
        "testY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d2d17a6d9a6d4bdf15e46ba4dd85415cd4defd55",
        "id": "vbt6b3ez4OgE"
      },
      "source": [
        "# plot some test image with there predicted label\n",
        "finalY = np.argmax(testY,axis=1)\n",
        "plot_figures(testX,finalY,nrows = 3, ncols=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d500511a6b007b274ce56490d99566a7080031f5",
        "id": "RtpoN-P-4OgF"
      },
      "source": [
        "# save submission file \n",
        "frame = pd.DataFrame({'Label': finalY.T.squeeze()})\n",
        "frame = frame.reset_index(drop=True)\n",
        "frame.index += 1 \n",
        "frame.to_csv(\"Digite Recognize.csv\", index_label='ImageId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "c25e0f89ab06a8b23236a39845d52d0e9d32d782",
        "collapsed": true,
        "id": "M0cyJ59N4OgF"
      },
      "source": [
        "print(frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "cb31e251756953cd287171e18e69421ca7653fc0",
        "id": "03QNWoAz4OgF"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOm3xczEI4sR",
        "outputId": "86cc70e8-bddb-4682-8818-d413475edc13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0WcymebI7FY"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/MNIST-params/base-model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijGS2YwZJBMo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}